# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17k4HnkpgcPnZ1WrkhWTyWarDS_1Hromx
"""

import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

df_test = pd.read_csv("/content/career_recommender.csv")

df_test.head()

df_test.isnull().sum()

df_test['What are your skills ? (Select multiple if necessary)'].mode()

"""# New Section"""

df_test['What are your skills ? (Select multiple if necessary)'].fillna(df_test['What are your skills ? (Select multiple if necessary)'].mode()[0],inplace=True)

df_test['If yes, then what is/was your first Job title in your current field of work? If not applicable, write NA.               '].mode()

df_test['If yes, then what is/was your first Job title in your current field of work? If not applicable, write NA.               '].fillna(df_test['If yes, then what is/was your first Job title in your current field of work? If not applicable, write NA.               '].mode()[0],inplace=True)

df_test['Have you done masters after undergraduation? If yes, mention your field of masters.(Eg; Masters in Mathematics)'].mode()

df_test['Have you done masters after undergraduation? If yes, mention your field of masters.(Eg; Masters in Mathematics)'].fillna(df_test['Have you done masters after undergraduation? If yes, mention your field of masters.(Eg; Masters in Mathematics)'].mode()[0],inplace=True)

df_test.isnull().sum()

column_dict= {'What is your name?': 'Name',
               'What is your gender?': 'Gender',
               'What was your course in UG?': 'Course',
               'What is your UG specialization? Major Subject (Eg; Mathematics)': 'Specialization',
               'What are your interests?': 'Interest',
               'What are your skills ? (Select multiple if necessary)': 'Skills',
               'What was the average CGPA or Percentage obtained in under graduation?': 'Grades',
               'Did you do any certification courses additionally?': 'Any_Add_Cert_Courses',
               'If yes, please specify your certificate course title.': 'Cert_Courses_Desc',
               'Are you working?': 'Working?',
               'If yes, then what is/was your first Job title in your current field of work? If not applicable, write NA.               ': 'Job_Title',
               'Have you done masters after undergraduation? If yes, mention your field of masters.(Eg; Masters in Mathematics)': 'Masters_Desc'}

# Rename the columns using the dictionary
df_test = df_test.rename(columns=column_dict)

print(df_test.columns)

df_test.drop(['Name', 'Specialization', 'Any_Add_Cert_Courses', 'Cert_Courses_Desc', 'Working?', 'Job_Title', 'Masters_Desc'], axis=1, inplace=True)

print(df_test.columns)

pip install klib

import klib

klib.convert_datatypes(df_test)

klib.clean_column_names(df_test)

klib.data_cleaning(df_test)

klib.mv_col_handling(df_test)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df_test['gender'] = le.fit_transform(df_test['gender'])
df_test['course'] = le.fit_transform(df_test['course'])

df_test['interest'] = df_test['interest'].apply(lambda x: [interest.lower().strip() for interest in x.replace(';', ',').split(',')])
df_test['skills'] = df_test['skills'].apply(lambda x: [skill.lower().strip() for skill in x.replace(';', ',').split(',')])

from sklearn.preprocessing import MultiLabelBinarizer
mlb = MultiLabelBinarizer()

mlb_interest = MultiLabelBinarizer()
mlb_skills = MultiLabelBinarizer()

# perform multihot encoding on each column separately
encoded_interest = mlb_interest.fit_transform(df_test['interest'])
encoded_skills = mlb_skills.fit_transform(df_test['skills'])

# concatenate the encoded arrays with the original dataframe
df_test = pd.concat([df_test, pd.DataFrame(encoded_interest, columns=mlb_interest.classes_), pd.DataFrame(encoded_skills, columns=mlb_skills.classes_)], axis=1)

# remove the original columns from the encoded dataframe
df_test.drop(['interest', 'skills'], axis=1, inplace=True)

df_test.shape

df_test

import joblib

joblib.dump(le,r'le.pkl')
joblib.dump(mlb,r'mlb.pkl')

corr_matrix = df_test.corr()

# Display the correlation matrix
print(corr_matrix)

X=df_test.drop('course',axis=1)

Y=df_test['course']

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=101, test_size=0.2)

X.describe()

from sklearn.preprocessing import StandardScaler
sc= StandardScaler()

X_train_std= sc.fit_transform(X_train)

X_test_std= sc.transform(X_test)
X_train_std

X_test_std

Y_train

Y_test

joblib.dump(sc,r'sc.sav')

from sklearn.linear_model import LinearRegression
lr= LinearRegression()

lr.fit(X_train_std,Y_train)

X_test.head()

Y_pred_lr=lr.predict(X_test_std)

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
print(r2_score(Y_test,Y_pred_lr))
print(mean_absolute_error(Y_test,Y_pred_lr))
print(np.sqrt(mean_squared_error(Y_test,Y_pred_lr)))

joblib.dump(lr,r'lr.sav')

from sklearn.ensemble import RandomForestRegressor
rf= RandomForestRegressor()

rf.fit(X_train,Y_train)

Y_pred_rf= rf.predict(X_test)

print(r2_score(Y_test,Y_pred_rf))
print(mean_absolute_error(Y_test,Y_pred_rf))
print(np.sqrt(mean_squared_error(Y_test,Y_pred_rf)))

joblib.dump(rf,r'rf.sav')

from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import GridSearchCV

# define models and parameters
model = RandomForestRegressor()
n_estimators = [10, 100, 1000]
max_depth=range(1,31)
min_samples_leaf=np.linspace(0.1, 1.0)
max_features=["auto", "sqrt", "log2"]
min_samples_split=np.linspace(0.1, 1.0, 10)

# define grid search
grid = dict(n_estimators=n_estimators, max_depth=max_depth)

#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=101)

grid_search_forest = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,
                           scoring='r2',error_score=0,verbose=2,cv=2)

grid_search_forest.fit(X_train_std, Y_train)

# summarize results
print(f"Best: {grid_search_forest.best_score_:.3f} using {grid_search_forest.best_params_}")
means = grid_search_forest.cv_results_['mean_test_score']
stds = grid_search_forest.cv_results_['std_test_score']
params = grid_search_forest.cv_results_['params']

for mean, stdev, param in zip(means, stds, params):
    print(f"{mean:.3f} ({stdev:.3f}) with: {param}")

joblib.dump(grid_search_forest,r'grid_search_forest.sav')